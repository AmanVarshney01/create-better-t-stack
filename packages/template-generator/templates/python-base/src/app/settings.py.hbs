{{#if (eq pythonValidation "pydantic")}}
"""Application settings using pydantic-settings."""

from functools import lru_cache

from pydantic_settings import BaseSettings, SettingsConfigDict


class Settings(BaseSettings):
    """Application settings loaded from environment variables."""

    model_config = SettingsConfigDict(
        env_file=".env",
        env_file_encoding="utf-8",
        case_sensitive=False,
    )

    # Application settings
    app_name: str = "{{projectName}}"
    debug: bool = False
    host: str = "0.0.0.0"
    port: int = 8000

    # API settings
    api_prefix: str = "/api"
    api_version: str = "v1"

{{#if (or (eq pythonOrm "sqlalchemy") (eq pythonOrm "sqlmodel"))}}
    # Database settings
    database_url: str = "sqlite:///./app.db"
{{/if}}
{{#if (includes pythonAi "openai-sdk")}}
    # OpenAI settings
    openai_api_key: str = ""
    openai_default_model: str = "gpt-4o-mini"
    openai_default_temperature: float = 0.7
{{/if}}
{{#if (includes pythonAi "anthropic-sdk")}}
    # Anthropic settings
    anthropic_api_key: str = ""
    anthropic_default_model: str = "claude-sonnet-4-20250514"
    anthropic_default_max_tokens: int = 4096
    anthropic_default_temperature: float = 0.7
{{/if}}
{{#if (includes pythonAi "langchain")}}
    # LangChain settings
    openai_api_key: str = ""
    langchain_default_model: str = "gpt-4o-mini"
    langchain_default_temperature: float = 0.7
{{/if}}
{{#if (includes pythonAi "llamaindex")}}
    # LlamaIndex settings
    openai_api_key: str = ""
    llamaindex_default_model: str = "gpt-4o-mini"
    llamaindex_default_temperature: float = 0.7
    llamaindex_embed_model: str = "text-embedding-3-small"
{{/if}}
{{#if (includes pythonAi "langgraph")}}
    # LangGraph settings
    openai_api_key: str = ""
    langgraph_default_model: str = "gpt-4o-mini"
    langgraph_default_temperature: float = 0.7
    langgraph_max_iterations: int = 10
{{/if}}
{{#if (includes pythonAi "crewai")}}
    # CrewAI settings
    openai_api_key: str = ""
    crewai_verbose: bool = True
{{/if}}
{{#if (eq pythonTaskQueue "celery")}}
    # Celery settings
    celery_broker_url: str = "redis://localhost:6379/0"
    celery_result_backend: str = "redis://localhost:6379/0"
{{/if}}


@lru_cache
def get_settings() -> Settings:
    """Get cached settings instance."""
    return Settings()
{{/if}}
