{{#if (eq ai "langgraph")}}
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { HumanMessage, AIMessage, type BaseMessage } from "@langchain/core/messages";
import { createReactAgent } from "@langchain/langgraph/prebuilt";

export const maxDuration = 30;

const model = new ChatGoogleGenerativeAI({
	model: "gemini-2.0-flash",
	temperature: 0,
});

const agent = createReactAgent({
	llm: model,
	tools: [],
});

export async function POST(req: Request) {
	const { messages } = await req.json();

	const langchainMessages: BaseMessage[] = messages.map((msg: { role: string; content: string }) => {
		if (msg.role === "user") {
			return new HumanMessage(msg.content);
		}
		return new AIMessage(msg.content);
	});

	const stream = await agent.stream(
		{ messages: langchainMessages },
		{ streamMode: "messages" }
	);

	const encoder = new TextEncoder();
	const readable = new ReadableStream({
		async start(controller) {
			try {
				for await (const [message] of stream) {
					if (message.content) {
						const content = typeof message.content === "string"
							? message.content
							: JSON.stringify(message.content);
						controller.enqueue(encoder.encode(`data: ${JSON.stringify({ content })}\n\n`));
					}
				}
				controller.enqueue(encoder.encode("data: [DONE]\n\n"));
				controller.close();
			} catch (error) {
				controller.error(error);
			}
		},
	});

	return new Response(readable, {
		headers: {
			"Content-Type": "text/event-stream",
			"Cache-Control": "no-cache",
			Connection: "keep-alive",
		},
	});
}
{{else}}
import { google } from "@ai-sdk/google";
import { streamText, type UIMessage, convertToModelMessages, wrapLanguageModel } from "ai";
import { devToolsMiddleware } from "@ai-sdk/devtools";

export const maxDuration = 30;

export async function POST(req: Request) {
	const { messages }: { messages: UIMessage[] } = await req.json();

	const model = wrapLanguageModel({
		model: google("gemini-2.5-flash"),
		middleware: devToolsMiddleware(),
	});
	const result = streamText({
		model,
		messages: await convertToModelMessages(messages),
	});

	return result.toUIMessageStreamResponse();
}
{{/if}}
