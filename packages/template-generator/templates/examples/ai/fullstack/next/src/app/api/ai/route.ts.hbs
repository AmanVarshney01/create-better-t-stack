{{#if (eq ai "langgraph")}}
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { HumanMessage, AIMessage, type BaseMessage } from "@langchain/core/messages";
import { createReactAgent } from "@langchain/langgraph/prebuilt";

export const maxDuration = 30;

const model = new ChatGoogleGenerativeAI({
	model: "gemini-2.0-flash",
	temperature: 0,
});

const agent = createReactAgent({
	llm: model,
	tools: [],
});

export async function POST(req: Request) {
	const { messages } = await req.json();

	const langchainMessages: BaseMessage[] = messages.map((msg: { role: string; content: string }) => {
		if (msg.role === "user") {
			return new HumanMessage(msg.content);
		}
		return new AIMessage(msg.content);
	});

	const stream = await agent.stream(
		{ messages: langchainMessages },
		{ streamMode: "messages" }
	);

	const encoder = new TextEncoder();
	const readable = new ReadableStream({
		async start(controller) {
			try {
				for await (const [message] of stream) {
					if (message.content) {
						const content = typeof message.content === "string"
							? message.content
							: JSON.stringify(message.content);
						controller.enqueue(encoder.encode(`data: ${JSON.stringify({ content })}\n\n`));
					}
				}
				controller.enqueue(encoder.encode("data: [DONE]\n\n"));
				controller.close();
			} catch (error) {
				controller.error(error);
			}
		},
	});

	return new Response(readable, {
		headers: {
			"Content-Type": "text/event-stream",
			"Cache-Control": "no-cache",
			Connection: "keep-alive",
		},
	});
}
{{else if (eq ai "google-adk")}}
import { LlmAgent, Runner } from "@google/adk";

export const maxDuration = 30;

const agent = new LlmAgent({
	name: "chat_agent",
	model: "gemini-2.5-flash",
	description: "A helpful AI assistant that can answer questions and help with tasks.",
	instruction: "You are a helpful AI assistant. Respond to user queries in a clear and concise manner.",
	tools: [],
});

export async function POST(req: Request) {
	const { messages } = await req.json();

	const lastMessage = messages[messages.length - 1];
	const userMessage = lastMessage?.content || "";

	const runner = new Runner({ agent, appName: "chat-app" });
	const result = await runner.runAsync({ userMessage });

	let responseText = "";
	for await (const event of result) {
		if (event.content?.parts) {
			for (const part of event.content.parts) {
				if (part.text) {
					responseText += part.text;
				}
			}
		}
	}

	const encoder = new TextEncoder();
	const readable = new ReadableStream({
		start(controller) {
			controller.enqueue(encoder.encode(`data: ${JSON.stringify({ content: responseText })}\n\n`));
			controller.enqueue(encoder.encode("data: [DONE]\n\n"));
			controller.close();
		},
	});

	return new Response(readable, {
		headers: {
			"Content-Type": "text/event-stream",
			"Cache-Control": "no-cache",
			Connection: "keep-alive",
		},
	});
}
{{else}}
import { google } from "@ai-sdk/google";
import { streamText, type UIMessage, convertToModelMessages, wrapLanguageModel } from "ai";
import { devToolsMiddleware } from "@ai-sdk/devtools";

export const maxDuration = 30;

export async function POST(req: Request) {
	const { messages }: { messages: UIMessage[] } = await req.json();

	const model = wrapLanguageModel({
		model: google("gemini-2.5-flash"),
		middleware: devToolsMiddleware(),
	});
	const result = streamText({
		model,
		messages: await convertToModelMessages(messages),
	});

	return result.toUIMessageStreamResponse();
}
{{/if}}
